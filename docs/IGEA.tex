%! Author = Alessandro
%! Date = 09/01/2026

% Preamble
\documentclass[11pt]{article}

% --- PACCHETTI ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{changepage}
\usepackage{titlesec}
\usepackage{fancyhdr} % Per l'intestazione personalizzata
\usepackage{float}
\usepackage[none]{hyphenat}
\usepackage{parskip}
\usepackage[colorlinks=true,
    linkcolor=black, % L'indice resta nero
    urlcolor=blue,   % I link web diventano blu
    citecolor=black]{hyperref}
\usepackage{color}

% --- GEOMETRIA PAGINA ---
% headheight=40pt serve per fare spazio al logo nell'header
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm, headheight=40pt}

% --- DEFINIZIONE COLORI ---
\definecolor{igeaPurple}{HTML}{AE4FDD}

% --- CONFIGURAZIONE INTESTAZIONE (HEADER) ---
% Definiamo lo stile che apparirà su TUTTE le pagine tranne la copertina
\pagestyle{fancy}
\fancyhf{} % Pulisce header e footer precedenti

% 1. Logo a sinistra (Dip-Inf)
\lhead{\includegraphics[height=1.2cm]{images/dip-Inf.png}}

% 2. Testo a destra (Laurea e Prof. Palomba)
\rhead{\footnotesize
Laurea Triennale in Informatica - Università di Salerno \\
Corso di Fondamenti di Intelligenza Artificiale - Prof. F. Palomba}

% 3. Numero di pagina in basso al centro
\cfoot{\thepage}

% Ridefiniamo lo stile "plain" (usato dall'indice) per avere lo stesso header
\fancypagestyle{plain}{
    \fancyhf{}
    \lhead{\includegraphics[height=1.2cm]{images/dip-Inf.png}}
    \rhead{\footnotesize Laurea Triennale in Informatica - Università di Salerno \\ Corso di Fondamenti di Intelligenza Artificiale - Prof. F. Palomba}
    \cfoot{\thepage}
}

% --- INIZIO DOCUMENTO ---
\begin{document}

    % ==========================================
    %               COPERTINA
    % ==========================================
    % \thispagestyle{empty} Rimuove header, footer e numero pagina SOLO da questa pagina
    \begin{titlepage}
        \thispagestyle{empty}
        \centering

        % Testo Istituzionale (Come nella versione originale)
        \Large UNIVERSITÀ DEGLI STUDI DI SALERNO \\[0.5cm]
        \Large Corso di Laurea in Informatica \\
        \Large Fondamenti di Intelligenza Artificiale \\[1cm]

        % Logo del progetto IGEA
        \includegraphics[width=0.4\textwidth]{images/logo_IGEA} \\[0.5cm]

        % Titolo Progetto
        \Huge \textbf{IGEA}\\[0.5cm]

        % Autori
        \Large
        \textbf{Gruppo di Progetto:} \\[0.5cm]
        Gennaro Pio Albano (Mat. 0512119547) \\[0.3cm]
        Giuseppe Annunziata (Mat. 0512120144) \\[0.3cm]
        Alessandro Bonelli (Mat. 0512119640) \\[0.3cm]
        Samuele Nacchia (Mat. 0512119128) \\[1.5cm]

        % Logo Unisa in basso
        \includegraphics[width=0.2\textwidth]{images/unisa}

        \vfill
        \large Anno Accademico 2025/2026
    \end{titlepage}

    \newpage

    % ==========================================
    %               INDICE
    % ==========================================
    \tableofcontents
    \newpage

    % ==========================================
    %               CONTENUTO
    % ==========================================

    \section{Introduzione}

        Il benessere psicologico degli studenti universitari rappresenta una tematica di crescente rilevanza nel
        panorama accademico e sanitario. Il percorso universitario, spesso caratterizzato da elevate pressioni
        performative, transizioni sociali significative e incertezza verso il futuro, costituisce una fase critica
        che può favorire l'insorgenza di disturbi dell'umore, tra cui la depressione.\newline
        Tale disagio, se trascurato, può aggravarsi fino a livelli insostenibili, portando nei casi più drammatici a
        gesti estremi.


    \subsection{Sistema attuale}

        Attualmente, l’individuazione di studenti universitari a rischio di depressione avviene
        principalmente tramite autosegnalazione o osservazioni indirette da parte di docenti e tutor.\newline
        I servizi di supporto psicologico operano in maniera reattiva, intervenendo solo quando il disagio è
        già esplicitamente manifestato. Non sono presenti strumenti automatici di analisi o predizione basati sui dati,
        rendendo difficile un’identificazione precoce e sistematica degli studenti potenzialmente vulnerabili.


    \subsection{Obiettivi}

        Il sistema IGEA - Intelligent Guide for Emotional Assessment è stato progettato con l’obiettivo
        di fornire un supporto proattivo nella rilevazione precoce della depressione tra gli studenti universitari,
        al fine di favorire interventi tempestivi e mirati da parte dell'università e degli psicologi dell'ateneo.
        IGEA è un alleato nel monitoraggio del benessere psicologico, ma non sostituisce il lavoro degli esperti.
        Il sistema non ha l'intento di diagnosticare o curare la depressione, ma piuttosto di identificare segnali di
        rischio che possano indicare uno stato di disagio emotivo o mentale, permettendo una valutazione iniziale
        della salute psicologica degli studenti.


    % ------------------------------------------

    \newpage

    \section{Descrizione agente}
    Il sistema \textit{IGEA} è modellato come un agente intelligente di tipo
    \textbf{classificatore}, progettato per supportare l’individuazione precoce
    di potenziali stati di disagio psicologico negli studenti universitari.
    L’agente analizza le risposte fornite dagli studenti tramite questionari
    psicologici strutturati e produce una valutazione automatica del rischio
    di sintomi depressivi.

    \subsection{Specifica PEAS}
        Di seguito è riportata la descrizione PEAS dell'ambiente operativo in forma tabellare.

        \begin{table}[H]
            \centering
            \renewcommand{\arraystretch}{1.5} % Spaziatura righe
            \begin{tabular}{|l|p{10cm}|}
                \hline
                \textbf{Componente} & \textbf{Descrizione} \\
                \hline
                \textbf{Performance} & La misura di performance del sistema si basa sulla capacità
                                       dell'agente di distinguere correttamente studenti inclini alla
                                       depressione e studenti non inclini, con particolare attenzione
                                       all'identificazione accurata della classe Depressione (True). \\

                \hline
                \textbf{Environment} & L'ambiente consiste negli studenti universitari, i quali
                                       completano un questionario psicologico per valutare il loro benessere emotivo. \\

                \hline
                \textbf{Actuators} & Gli attuatori consistono in un sistema di classificazione che
                                     assegna un'etichetta (\("\)Depresso\("\) o \("\)Non depresso\("\)) e segnala
                                     gli studenti identificati come a rischio con una panoramica chiara dei diversi report.
                                     Questi attuatori permettono di attivare interventi per supportare gli studenti. \\

                \hline
                \textbf{Sensors} & I sensori consistono nelle risposte al questionario psicologico
                                   fornito dagli studenti, che vengono analizzate dal sistema. \\
                \hline
            \end{tabular}
            \caption{Specifica PEAS dell'agente IGEA}\label{tab:table}
        \end{table}


    \subsection{Specifiche dell'ambiente}

        L’ambiente operativo in cui agisce il sistema \textit{IGEA}
        è costituito dall’insieme dei dati relativi agli studenti universitari, provenienti da questionari
        autocompilati. Il modello di machine learning interagisce con tale ambiente analizzando i dati disponibili
        al fine di stimare il livello di rischio di disagio psicologico, con particolare riferimento a stati
        depressivi.

        L’ambiente di IGEA può essere classificato come segue:

        \begin{itemize}
            \item \textbf{Parzialmente osservabile}:
            l’agente non ha accesso diretto allo stato psicologico reale dello studente, ma solo a informazioni
            indirette e parziali, spesso soggettive e rumorose, come risposte a questionari.
            Di conseguenza, lo stato dell’ambiente non è completamente osservabile.

            \item \textbf{Non deterministico}:
            la relazione tra i dati osservabili e il reale stato emotivo dello studente non è deterministica.
            A parità di input possono corrispondere stati psicologici differenti, a causa di fattori esterni
            non completamente modellabili e dell’elevata variabilità individuale.

            \newpage
            \item \textbf{Episodico}:
            ogni valutazione prodotta dal sistema è indipendente dalle precedenti.\newline Il modello analizza le
            osservazioni raccolte in un determinato istante temporale senza mantenere uno stato interno che
            tenga traccia delle valutazioni passate. Ciascun episodio corrisponde pertanto a una singola
            compilazione del questionario, e la decisione non influenza né dipende da episodi futuri.

            \item \textbf{Statico}:
            durante l’elaborazione dei dati relativi a una singola compilazione del questionario, l’ambiente
            non cambia: le percezioni fornite all’agente e lo stato interno considerato restano invariati fino al
            termine dell’analisi. Eventuali variazioni nello stato emotivo dello studente o nei dati disponibili
            si verificano solo tra episodi distinti, e non influenzano il processo decisionale in corso.

            \item \textbf{Discreto}:
            poiché il sistema produce esclusivamente una classificazione binaria e opera su percezioni,
            stati e azioni discreti

            \item \textbf{Singolo agente}:
            il sistema IGEA opera come agente singolo e non interagisce direttamente con altri agenti
            intelligenti. Esso fornisce supporto decisionale a figure umane quali psicologi e servizi di
            supporto universitari, che rimangono responsabili degli interventi finali.
        \end{itemize}

    % ------------------------------------------

    \section{Individuazione dataset }
    Nella fase iniziale del progetto, sono state valutate due diverse strategie per l'acquisizione dei
    dati necessari all'addestramento del modello di Machine Learning:
    \begin{enumerate}
        \item \textbf{Creare} un dataset da zero, sottoponendo un questionario ad un campione di studenti;

        \item \textbf{Cercare} sulla rete un dataset già formato,
                    e adeguarlo alle nostre esigenze;

    \end{enumerate}

    Dopo un'analisi comparativa, la prima opzione è stata scartata a causa di limitazioni metodologiche
    critiche. In primo luogo, la raccolta di un numero di campioni statisticamente significativo avrebbe
    richiesto tempi eccessivamente lunghi.

    Tuttavia, l'ostacolo principale è rappresentato dalla \textbf{mancanza di un esperto di dominio}.\newline
    Per addestrare un modello di classificazione accurato, ogni record deve essere etichettato correttamente
    (es. "Depresso: Sì/No"). Senza la supervisione di un professionista in grado di valutare clinicamente
    le risposte dei candidati, il dataset prodotto sarebbe risultato privo di validità scientifica,
    rendendo il modello inaffidabile.

    Di conseguenza, si è deciso di procedere con la seconda soluzione, individuando sulla
    piattaforma \textbf{Kaggle} il dataset: \href{https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset/data}{\textcolor{blue}{\underline{\textit{"Student Depression Dataset"}}}}



    \subsection{Punti di forza del dataset}
    La scelta è ricaduta su questo archivio per i seguenti motivi:
    \begin{itemize}
        \item \textbf{Varietà dei parametri:}
            Include fattori determinanti come la pressione accademica,
            la soddisfazione nello studio, le ore di sonno e la storia clinica familiare.
        \item \textbf{Ampiezza dei dati:} Le migliaia di osservazioni forniscono una base solida
            per l'addestramento, permettendo all'algoritmo di riconoscere pattern complessi con
            maggiore precisione.
    \end{itemize}

    % ------------------------------------------

    \subsection{Limiti del dataset}
    Tale dataset presenta i seguenti limiti:
    \begin{itemize}

        \item
        \textbf{Provenienza culturale}: Il dataset proviene da studenti indiani, e le esperienze psicologiche e
        comportamentali potrebbero differire da quelle degli studenti italiani, influenzando i risultati.

        \item
        \textbf{Fattori socio-culturali e accademici}: Sebbene il dataset descriva variabili psicologiche e
        comportamentali legate alla vita universitaria (che non sono specifiche di un singolo contesto nazionale),
        le dinamiche socio-culturali e accademiche in India potrebbero comunque influenzare la rilevazione del rischio di depressione.

        \item
        \textbf{Validità limitata}: Senza una validazione su dati italiani, il modello potrebbe non riflettere
        accuratamente il rischio di depressione tra gli studenti italiani.

    \end{itemize}

    Sebbene il dataset quindi sia stato raccolto su studenti indiani, le informazioni disponibili
    descrivono aspetti psicologici e comportamentali legati alla vita universitaria che non sono
    specifici di un singolo contesto nazionale. Il modello viene pertanto utilizzato come studio
    preliminare per valutare la fattibilità di un sistema predittivo del rischio di depressione,
    riconoscendo che una validazione su dati italiani reali sarebbe necessaria per un impiego operativo.


% ==========================================
%          DATA UNDERSTANDING
% ==========================================
    \section{Data Understanding}

    Prima di procedere con le  fasi di preparazione dei dati, è stata svolta una fase di \textit{data understanding},
    con l’obiettivo di comprendere la struttura del dataset, il significato delle variabili e la loro coerenza con il
    dominio applicativo del sistema.

    In questa fase sono state analizzate tutte le colonne del dataset, identificandone il ruolo e il tipo di
    informazione rappresentata. In particolare, le variabili sono state suddivise nelle seguenti categorie:

    \begin{itemize}
        \item \textbf{Variabili demografiche}: \textit{Gender}, \textit{Age};
        \item \textbf{Variabili psicologiche e autovalutative}: \textit{Academic Pressure}, \textit{Study Satisfaction}, \textit{Job Satisfaction}, \textit{Have you ever had suicidal thoughts?}, \textit{Family History of Mental Illness}, \textit{Financial Stress};
        \item \textbf{Variabili di contesto accademico e personale}: \textit{Degree}, \textit{Profession}, \textit{Work/Study Hours}, \textit{CGPA}, \textit{Sleep Duration}, \textit{Dietary Habits}, \textit{Work Pressure}, \textit{City}.
    \end{itemize}

    È stata inoltre individuata la variabile target del problema di classificazione, identificata nella colonna
    \textit{Depression}, che rappresenta se lo studente è a rischio di depressione.

    \paragraph{Descrizione semantica delle variabili}

    La Tabella~\ref{tab:semantic_features} riporta una breve descrizione semantica delle variabili presenti nel
    dataset, al fine di chiarirne il significato e il ruolo nel contesto del problema affrontato.

    \begin{table}[H]
        \centering
        \begin{tabular}{|l|p{10cm}|}
            \hline
            \textbf{Variabile} & \textbf{Descrizione semantica} \\
            \hline
            Gender & Genere dichiarato dallo studente. \\
            Age & Età dello studente espressa in anni. \\
            Academic Pressure & Livello di pressione percepita legata alle attività accademiche. \\
            Study Satisfaction & Livello di soddisfazione dello studente rispetto allo studio. \\
            Job Satisfaction & Livello di soddisfazione rispetto ad attività lavorative eventualmente svolte. \\
            CGPA & Media accademica di tutti i voti ottenuti nel percorso di studi. \\
            Work/Study Hours & Numero medio di ore dedicate quotidianamente a studio e lavoro. \\
            Sleep Duration & Durata media del sonno giornaliero dichiarata. \\
            Dietary Habits & Indicatore delle abitudini alimentari dichiarate. \\
            Degree & Livello di istruzione dichiarato dallo studente. \\
            Financial Stress & Livello di stress percepito legato alla situazione finanziaria. \\
            Have you ever had suicidal thoughts? & Indicatore della presenza di pensieri suicidari auto-riferiti. \\
            Family History of Mental Illness & Presenza di precedenti familiari di disturbi mentali. \\
            Profession & Stato occupazionale dichiarato (nel dataset: Student). \\
            City & Città di residenza dichiarata dallo studente. \\
            Depression & Variabile target che indica la presenza o assenza di depressione. \\
            \hline
        \end{tabular}
        \caption{Descrizione semantica delle variabili del dataset}
        \label{tab:semantic_features}
    \end{table}

    Questa fase di data understanding ha consentito di validare la coerenza del dataset rispetto all’obiettivo
    del sistema e di impostare correttamente l’analisi preliminare e le successive fasi di preparazione dei dati,
    senza introdurre modifiche al dataset originale.






    \subsection{Analisi preliminare del dataset}
    L’analisi preliminare del dataset per comprenderne la struttura e le principali caratteristiche statistiche
    si è concentrata su:

    \begin{itemize}
        \item controllo del bilanciamento dei dati.
        \item calcolo della dipendenza delle feature numeriche e categoriche dalla variabile target \textit{Depression};
        \item analisi delle distribuzioni delle feature numeriche e categoriche per identificare variabili sbilanciate o a bassa variabilità.
        \item identificazione di possibili data leakage.
    \end{itemize}

    \newpage

    \paragraph{Bilanciamento dei dati}
    La Tabella~\ref{tab:class_distribution_depression_pct} riporta la distribuzione delle osservazioni tra le due classi della variabile
    target \textit{Depression}, da cui si osserva un moderato sbilanciamento a favore della classe positiva.
    \begin{table}[h]
        \centering
        \caption{Distribuzione delle classi della variabile target \textit{Depression}}
        \label{tab:class_distribution_depression_pct}
        \begin{tabular}{lcc}
            \hline
            \textbf{Classe} & \textbf{Numero di elementi} & \textbf{Percentuale (\%)} \\
            \hline
            Depressi (1)      & 16336 & 58.55 \\
            Non depressi (0)  & 11565 & 41.45 \\
            \hline
            Totale            & 27901 & 100.00 \\
            \hline
        \end{tabular}
    \end{table}



    \paragraph{Dipendenza dalla variabile target}

    Per le feature numeriche, è stata calcolata la correlazione di Pearson con la variabile target.
    Per le feature categoriche, la dipendenza è stata stimata come la massima differenza
    tra le percentuali di studenti depressi e non depressi all'interno delle categorie di ciascuna variabile.
    In altre parole, indica quanto la presenza di una determinata categoria sia associata allo stato di depressione.

    I risultati principali sono i seguenti:

    \textbf{Correlazione delle feature numeriche con la target \textit{Depression}:}
    \begin{itemize}
        \item Academic Pressure: 0.475
        \item Age: -0.226
        \item Work/Study Hours: 0.209
        \item Study Satisfaction: -0.168
        \item CGPA: 0.022
        \item Job Satisfaction: -0.003
        \item Work Pressure: -0.003
        \item id: 0.001
    \end{itemize}

    \textbf{Correlazione delle feature categoriche con la target \textit{Depression}:}
    \begin{itemize}
        \item City: 1.000
        \item Profession: 1.000
        \item Financial Stress: 0.626
        \item Have you ever had suicidal thoughts ?: 0.581
        \item Degree: 0.415
        \item Dietary Habits: 0.415
        \item Sleep Duration: 0.290
        \item Family History of Mental Illness: 0.225
        \item Gender: 0.173
    \end{itemize}

    \paragraph{Analisi delle distribuzioni}

    Per ciascuna feature, oltre a valutare la correlazione o la dipendenza dalla target, è stata analizzata la distribuzione dei valori:

    \begin{itemize}
        \item \textbf{Feature numeriche}: sono state calcolate media, deviazione standard, skewness e kurtosis.
        Feature con skew > 1, kurtosis > 5 o deviazione standard molto bassa (<0.01) sono state considerate \textit{anomale},
        poiché potrebbero non fornire informazioni significative al modello.
        \item \textbf{Feature categoriche}: sono state valutate la numerosità delle categorie e la distribuzione percentuale.
        Variabili con una sola categoria o con una categoria dominante (>90\%) sono considerate sbilanciate e poco informative.
    \end{itemize}

    \paragraph{Data leakage}
    Al fine di verificare la presenza di potenziali fenomeni di data leakage, è stata analizzata separatamente la feature
    \textit{Have you ever had suicidal thoughts ?} tramite una tabella di contingenza normalizzata rispetto alla variabile
    target \textit{Depression}. I risultati mostrano una dipendenza estremamente marcata tra le due variabili, suggerendo che la
    feature possa fornire informazione quasi deterministica sulla classe target.

    \begin{table}[h]
        \centering
        \caption{Distribuzione percentuale della variabile \textit{Depression} in funzione della feature \textit{Have you ever had suicidal thoughts ?}}
        \label{tab:suicidal_thoughts_depression_pct}
        \begin{tabular}{lcc}
            \hline
            \textbf{Have you ever had suicidal thoughts ?} & \textbf{Depression = 0 (\%)} & \textbf{Depression = 1 (\%)} \\
            \hline
            No  & 76.8 & 23.2 \\
            Yes & 21.0 & 79.0 \\
            \hline
        \end{tabular}
    \end{table}



    \section{Data preparation}
    Al fine di analizzare in modo più approfondito l’impatto delle scelte di preparazione dei dati sul comportamento
    e sulle prestazioni dei modelli di classificazione, sono state definite due pipeline alternative di preprocessing.
    L’obiettivo non è individuare una pipeline intrinsecamente migliore dell’altra, ma valutare come differenti strategie
    di selezione e trasformazione delle feature influenzino i risultati del sistema proposto.


    Le due pipeline rappresentano approcci complementari alla preparazione del dataset.

    La prima adotta una strategia basata sulla rimozione delle variabili potenzialmente
    ridondanti, poco informative o fortemente dipendenti dal contesto di origine del dataset.
    Questa pipeline consente di valutare le prestazioni dei modelli in una configurazione minimale,
    riducendo il rischio di bias e di dipendenza da specifiche assunzioni sul dominio.

    La seconda pipeline, invece, mantiene alcune variabili di contesto accademico,
    introducendo trasformazioni controllate volte a migliorarne l’interpretabilità e la trasferibilità
    nel contesto universitario di riferimento. In particolare, tale pipeline consente di analizzare
    l’effetto di una rappresentazione più informata dei dati, pur senza introdurre assunzioni forti o
    modifiche che alterino il significato originale delle informazioni.

    L’adozione di due pipeline permette quindi di:
    \begin{itemize}
        \item valutare la robustezza dei modelli rispetto a diverse scelte di preprocessing;
        \item analizzare la sensibilità dei modelli alla presenza o assenza di specifiche feature;
        \item confrontare le prestazioni dei modelli a parità di algoritmo, isolando l’effetto della preparazione dei dati;
        \item ottenere una valutazione sperimentale più solida e meno dipendente da una singola configurazione del dataset.
    \end{itemize}

    Per garantire un confronto corretto e controllato, gli stessi algoritmi di classificazione sono stati applicati
    a entrambe le pipeline. In questo modo, è possibile attribuire eventuali differenze nei risultati esclusivamente
    alle diverse strategie di preparazione dei dati, mantenendo invariata la componente di apprendimento.

    % ==========================================
    %              DATA CLEANING
    % ==========================================

    \subsection{Data cleaning}
    La fase di \textit{data cleaning} è finalizzata a rimuovere elementi potenzialmente dannosi per il processo
    di apprendimento del modello, con l’obiettivo di migliorare la qualità e l’affidabilità complessiva del dataset.
    Sono state eliminate la feature

    \begin{itemize}
        \item \textit{id}: attributo identificativo degli studenti, irrilevante per la predizione del rischio di depressione
        \item \textit{Have you ever had suicidal thoughts?}: considerata la natura semantica della feature,
        che rappresenta un sintomo clinico direttamente associato alla depressione e il rischio di performance
        artificialemnte gonfiate, la variabile è stata identificata come leaky predictor ed esclusa dalla fase di modellazione.
    \end{itemize}


    Successivamente, è stata condotta un’analisi dei valori mancanti. Dall’ispezione del dataset non sono emerse
    osservazioni con valori nulli, pertanto non si è resa necessaria alcuna operazione di imputazione o rimozione
    di record incompleti.

    È stato inoltre effettuato un controllo sulla presenza di osservazioni duplicate. Anche in questo caso,
    non sono state individuate righe duplicate, confermando la coerenza e l’unicità delle istanze presenti nel dataset.

    È stata inoltre condotta un’analisi dei valori anomali (\textit{outlier}) sulle variabili numeriche mediante
    il metodo dell’Interquartile Range (IQR). L’analisi ha evidenziato la presenza di 22 outlier nella variabile
    \textit{Age}, relativi a studenti con età significativamente superiore rispetto alla distribuzione centrale,
    3 outlier nella variabile \textit{Work Pressure}, 6 nella variabile \textit{CGPA} (valori pari a zero) e
    2 nella variabile \textit{Job Satisfaction}. Non sono stati rilevati outlier nelle restanti variabili numeriche.
    Complessivamente, la rimozione dei valori anomali ha comportato l’eliminazione di 33 osservazioni dal dataset.



    % ==========================================
    %              PIPELINE 1
    % ==========================================

    \subsection{Pipeline 1}

    \subsubsection{Feature engineering}

    \paragraph{Feature Construction}
    In questa fase, l'analisi si è spostata dalla semplice selezione delle variabili esistenti alla generazione di nuove feature sintetiche (\textit{Derived Features}). L'obiettivo è stato quello di catturare relazioni non lineari e interazioni complesse tra le variabili, basandosi su ipotesi derivanti dalla conoscenza del dominio psicologico (\textit{Domain Knowledge}).

    Si è ipotizzato che il rischio di depressione non dipenda unicamente dalla somma lineare dei singoli fattori di stress, ma dalla loro interazione sinergica, aggravata da condizioni fisiologiche precarie come la privazione del sonno. Per modellare questo fenomeno, sono state costruite le seguenti variabili.

    \paragraph{Calcolo del Debito di Sonno (Sleep Debt)}
    La variabile originale \texttt{Sleep Duration} presenta una relazione inversa rispetto al rischio depressivo (una maggiore durata del sonno è generalmente protettiva). Per allineare la metrica alla direzione del rischio e penalizzare specificamente la carenza di riposo, è stata introdotta la variabile \texttt{Sleep\_Debt}.

    Il debito è calcolato rispetto alla soglia raccomandata di 8 ore giornaliere. La funzione applicata assicura che valori superiori alle 8 ore non generino un debito negativo, ma siano considerati pari a zero.

    \begin{equation}
        \text{Sleep\_Debt} = \max(0, 8 - \text{Sleep Duration})
    \end{equation}

    Questa trasformazione permette al modello di quantificare linearmente la gravità della privazione del sonno, dove un valore più alto indica una condizione peggiore.

    \paragraph{Modellazione dello Stress Amplificato (Stress Amplified)}
    La principale innovazione introdotta nella pipeline è la variabile \texttt{Stress\_Amplified}.
    Questa feature nasce dall'ipotesi che la stanchezza cronica agisca come un \textbf{moltiplicatore dello stress}:
    la capacità di resilienza psicologica di uno studente diminuisce drasticamente all'aumentare del debito di sonno.

    Invece di considerare \texttt{Academic Pressure} e \texttt{Financial Stress} come addendi indipendenti,
    è stato modellato un termine di interazione in cui la pressione esterna totale viene amplificata
    dal fattore fisiologico del sonno:

    \begin{equation}
        \text{Pressione\_Totale} = \text{Academic Pressure} + \text{Financial Stress}
    \end{equation}

    \begin{equation}
        \text{Stress\_Amplified} = \text{Pressione\_Totale} \times (1 + \text{Sleep\_Debt})
    \end{equation}

    L'interpretazione della formula \((2)\) è la seguente:
    \begin{itemize}
        \item Se lo studente è riposato (\(\text{Sleep\_Debt} \approx 0\)),
            lo stress percepito coincide con la somma delle pressioni reali.
        \item All'aumentare del debito di sonno, il termine \((1 + \text{Sleep\_Debt})\) cresce,
            agendo come coefficiente moltiplicativo. Ad esempio, con 4 ore di debito,
            il carico di stress viene amplificato di un fattore 5.
    \end{itemize}

    Questa operazione di \textit{Feature Engineering} ha permesso di sintetizzare informazioni eterogenee
    in un unico indicatore ad alto potenziale predittivo, migliorando la capacità del modello di
    identificare soggetti a rischio che presentano una combinazione critica di stress moderato e
    grave deprivazione del sonno.

    \paragraph{Feature Selection}

    Inizialmente sono state rimosse le feature dipendenti dal contesto di origine del dataset:
    \begin{itemize}
        \item \textit{City}: rappresenta un'informazione geografica specifica del contesto indiano e quindi non generalizzabile agli studenti italiani.
        \item \textit{Degree}: poichè non relativa al contesto italiano
    \end{itemize}

    Successivamente, sono state rimosse le feature numeriche e categoriche con distribuzioni anomale o bassa dipendenza dalla target:

    \begin{itemize}
        \item \textbf{Numeriche}: Work Pressure, CGPA, Job Satisfaction
        \item \textbf{Categoriali}: Profession
    \end{itemize}

    Sono state inoltre rimosse le feature utilizzate per la creazione di \textit{Stress Amplified}:

    \begin{itemize}
        \item Academic Pressure, Financial Stress, Sleep Duration, Sleep Debt.
    \end{itemize}



    Al termine della fase di \textit{feature selection}, il dataset risultante appare coerente,
    privo di incongruenze significative e adeguato per le successive fasi di trasformazione e addestramento del modello.




    % ==========================================
    %              PIPELINE 2
    % ==========================================

    \subsection{Pipeline 2}

        La pipeline 2 mantiene le info accademiche ma le rende più trasferibili/leggibili,
        evitando variabili non trasferibili o ridondanti.

    \subsubsection{Feature engineering}
        \paragraph{Feature Transformation - Degree}
            La variabile \textit{Degree} descrive il livello di istruzione dichiarato dallo studente secondo il sistema educativo del paese di origine del dataset.
            Poiché tale rappresentazione risulta fortemente dipendente dal contesto accademico indiano e caratterizzata da un’elevata frammentazione delle categorie,
            è stata effettuata un’operazione di aggregazione in tre macro-categorie,
            basata esclusivamente sul livello di istruzione e non sul sistema universitario di riferimento.

            In particolare, i valori originali sono stati ricondotti alle seguenti categorie:
            \begin{itemize}
                \item \textbf{Diploma}: corrispondente al livello di istruzione secondaria superiore (es. \textit{Class 12});
                \item \textbf{Titolo di primo livello}: comprendente i titoli di livello bachelor;
                \item \textbf{Titolo di secondo livello}: comprendente i titoli di livello master e post-graduate.
            \end{itemize}

            Questa trasformazione consente di ridurre la dipendenza dal contesto accademico specifico del dataset,
            mantenendo al contempo un’informazione rilevante relativa al livello di istruzione dello studente.

    \paragraph{Feature Transformation - CGPA}

    La variabile \textit{CGPA} è espressa secondo una scala di valutazione specifica del sistema accademico di
    origine del dataset, nella quale valori più elevati corrispondono a prestazioni accademiche migliori.
    In particolare, secondo le specifiche del dataset, un valore di $10$ rappresenta il punteggio massimo,
    mentre un valore di $5$ corrisponde alla soglia minima di superamento.

    Al fine di rendere i valori maggiormente interpretabili nel contesto universitario italiano, la variabile è
    stata convertita in una rappresentazione su scala trentesimale. La conversione è stata effettuata mediante una
    trasformazione lineare, definita a partire dai punti di riferimento della scala ($10 \rightarrow 30$ e $5 \rightarrow 18$).
    La formula applicata è la seguente:

    \begin{equation}
        \text{CGPA_{30}}  = 2.4 \cdot \text{CGPA} + 6
    \end{equation}

    Tale trasformazione preserva l’ordine e le proprietà statistiche della variabile originale e non altera la sua capacità
    predittiva, ma ha esclusivamente una finalità descrittiva e interpretativa.

    Nel dataset finale, la variabile originale \textit{CGPA} è stata sostituita dalla nuova rappresentazione
    \textit{CGPA\_30}, al fine di evitare ridondanze informative.


    \paragraph{Feature Selection}
            Analogamente alla pipeline 1, è stata rimossa la feature \textbf {city}: fortemente dipendente dal contesto geografico
            indiano e quindi non generalizzabile ad altri contesti universitari;


            Mentre sono state escluse tra le feature caratterizzate da una bassa dipendenza dalla variabile target e da
            distribuzioni anomale:

            \begin{itemize}
                \item \textbf {Numeriche}: Work Pressure, Job Satisfaction
                \item \textbf {Categoriali}: Profession
            \end{itemize}
    
    \subsubsection{Feature Scaling}
        Per garantire che tutte le feature abbiano la stessa importanza, si è deciso di normalizzare
        le feature numeriche con media 0 e deviazione standard 1 attraverso l'adozione del \textbf{Z-score scaling}.
        Ciò consente di trasformare i dati in una forma che sia uniforme e comparabile, evitando che le variabili
        con valori estremi o unità diverse abbiano un impatto sproporzionato.
        Le feature scalate sono:
        \begin{itemize}
            \item \textit {Age}
            \item \textit {Academic Pressure}
            \item \textit {Study Satisfaction}
            \item \textit {Work/Study Hours}
            \item \textit {CGPA\_30}
        \end{itemize}

    \subsubsection{Encoding}
        Poiché la maggior parte dei modelli di machine learning opera su numeri si è deciso di convertire
        le variabili categoriche in variabili binarie attraverso l'adozione del \textbf{One-Hot encoder}.
        Ciò permette al modello di catturare le differenze tra le categorie senza pregiudizi, trattando ognuna
        come indipendente e riducendo il rischio di interpretare erroneamente le relazioni tra categorie diverse.
        Le feature trasformate sono:
        \begin{itemize}
            \item \textit {Gender}
            \item \textit {Sleep Duration}
            \item \textit {Dietary Habits}
            \item \textit {Financial Stress}
            \item \textit {Family History of Mental Illness}
            \item \textit {Degree\_level}
        \end{itemize}

% ------------------------------------------

    \section{Modeling}

    \subsection{Scelta degli Algoritmi}
        Sono stati selezionati due algoritmi di classificazione appartenenti a paradigmi
        differenti: la \textbf{Logistic Regression} e il \textbf{Decision Tree}.
        La scelta è motivata dalla necessità di bilanciare accuratezza predittiva e trasparenza
        nell'analisi dei fattori di rischio.

        \paragraph{Logistic Regression}
            La Logistic Regression rappresenta il modello \textit{baseline} per eccellenza nei problemi di
            classificazione binaria. Le ragioni della sua inclusione nel progetto sono le seguenti:

            \begin{itemize}
                \item \textbf{Interpretabilità:} Attraverso l'analisi dei coefficienti $\beta$,
                il modello permette di quantificare l'impatto relativo di ogni feature sulla probabilità del target.
                \item \textbf{Natura Probabilistica:} Il modello restituisce un valore continuo nell'intervallo $[0, 1]$.
                Questo approccio è fondamentale in ambito psicologico per valutare il grado di confidenza della previsione.
                \item \textbf{Ottimizzazione:} Il modello beneficia della standardizzazione delle feature effettuata
                nella pipeline di modelling, garantendo una convergenza efficiente dell'algoritmo di ottimizzazione.
            \end{itemize}

        \paragraph{Decision Tree}
            Il Decision Tree è un algoritmo di apprendimento supervisionato non parametrico che modella
            le decisioni attraverso una struttura gerarchica ad albero. A differenza della regressione
            logistica, non assume una relazione lineare tra le variabili.

            L'inclusione di questo algoritmo è giustificata dai seguenti punti:

            \begin{itemize}
                \item \textbf{Interpretabilità visuale:} La struttura a nodi e rami permette di
                visualizzare chiaramente le regole decisionali che conducono a una classificazione.
                In ambito clinico, ciò facilita l'identificazione di soglie critiche nelle risposte
                ai questionari.
                \item \textbf{Cattura delle interazioni:} Il modello è in grado di identificare
                automaticamente interazioni complesse tra le variabili senza la necessità di
                specificarle manualmente in fase di feature engineering.
                \item \textbf{Assenza di assunzioni distribuzionali:} I Decision Tree non richiedono
                che i dati seguano una distribuzione specifica e risultano poco sensibili alla scala
                delle feature, offrendo una prospettiva complementare alla Logistic Regression.
            \end{itemize}

    \subsection{Train-Test Split}

        Per valutare in modo robusto la capacità di generalizzazione dei modelli e ridurre il rischio di
        \textit{overfitting}, è stata adottata la metodologia di \textbf{k-fold cross validation}
        con $k = 5$.

        Questa tecnica prevede la suddivisione del dataset in $k$ sottoinsiemi (fold) di dimensione
        approssimativamente uguale. Per ciascuna iterazione, un fold viene utilizzato come insieme di
        validazione, mentre i restanti $k-1$ fold costituiscono il training set.
        Il processo viene ripetuto $k$ volte, consentendo a ciascun sottoinsieme di essere utilizzato
        esattamente una volta come dati di validazione.

        \paragraph{Riproducibilità}

    \subsection{Feature Scaling}
    Al fine di garantire che tutte le variabili numeriche contribuiscano equamente al processo di apprendimento,
    è stata applicata la tecnica della \textbf{Standardizzazione} (Z-score normalization).
    Tale procedura è fondamentale per algoritmi come la \textit{Logistic Regression},
    i cui processi di ottimizzazione sono sensibili alla scala dei dati.
    Questa trasformazione proietta i dati su una scala con \textbf{media 0} e \textbf{varianza 1},
    eliminando le disparità tra variabili con unità di misura differenti.
    Coerentemente con le buone pratiche di Machine Learning,
    i parametri dello scaler sono stati calcolati esclusivamente sul \textit{Training Set}
    per evitare fenomeni di \textit{Data Leakage}.

    \subsection{Data Balancing}
    Il dataset non presenta uno sbilanciamento marcato delle classi; tuttavia,
    per aumentare la robustezza del modello durante la fase di addestramento,
    è stato utilizzato il parametro \textit{class weight='balanced'}.
    Questo metodo assegna automaticamente pesi inversamente proporzionali
    alla frequenza delle classi, consentendo di mitigare eventuali effetti
    dello sbilanciamento senza modificare la distribuzione originale dei dati.

    \subsection{Implementazione/addestramento}

% ------------------------------------------

    \section{Conclusioni}
    Scrivere qui le conclusioni...

    \subsection{Metriche di valutazioni}
    Scrivere qui le metriche...

    \subsection{Valutazioni}
    Scrivere qui le valutazioni...

    \subsection{Considerazioni finali}
    Scrivere qui le considerazioni...

\end{document}